---
title: "Analyse des Vins Blancs"
output: html_document
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(dplyr)
library(caret)
library(randomForest)
library(corrplot)
library(rpart)
```

```{r dataset_analysis}
# Charger le jeu de données
winequality_white <- read_delim("dataset/winequality-white.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE)

# Normaliser les noms des colonnes
colnames(winequality_white) <- make.names(colnames(winequality_white))

print(colnames(winequality_white))

# Afficher les dernières lignes du jeu de données
kable(tail(winequality_white))

# Statistiques descriptives
summary(winequality_white)

# Calculer la matrice de corrélation
correlation_matrix <- cor(winequality_white)

# Visualiser la matrice de corrélation
corrplot(correlation_matrix, method = "circle")
```

### Interpreting the results:

This correlation plot shows clearly the correlations between variables.

- A positive correlation (shades of blue) means that if one the variables' value increases, the other increases.
- A negative correlation (shades of red) means that if one of the variables' value increases, the other decreases.

Obviously, wine density is inversely correlated to alcohol content. This can be easily understood when comparing the density of ethanol to that of water:

- Ethanol density : 0.7892 g/mL at 20°C.
- Water density : 0.9982 g/mL at 20°C.

And indeed, if alcohol content is higher, the density lowers, which explains the strong negative correlation.

```{r }
# Calculer la matrice de corrélation
correlation_pairs_matrix <- pairs(winequality_white)

# Test de normalité (Shapiro-Wilk)
shapiro.test(winequality_white$quality)

# Créer une variable binaire pour la qualité
winequality_white$quality_binary <- ifelse(winequality_white$quality >= 6, "Good", "Bad")

# Effectuer le test t de Student
t.test(`alcohol` ~ quality_binary, data = winequality_white)
```

```{r}
# Séparer les données en ensembles d'entraînement et de test
set.seed(123)
trainIndex <- createDataPartition(winequality_white$quality, p = .8,
                                  list = FALSE,
                                  times = 1)
wineTrain <- winequality_white[ trainIndex,]
wineTest  <- winequality_white[-trainIndex,]

wineTrain <- wineTrain[, !(names(wineTrain) %in% c("quality_binary"))]

dim(wineTrain)
dim(wineTest)
```

## Decision Tree Model
```{r}
# Entraîner le modèle avec un seul arbre de décision
tree_model <- rpart(quality ~ ., data = wineTrain, method = "class")

# Afficher l'arbre de décision
print(tree_model)

# Faire des prédictions sur l'ensemble de test
tree_predictions <- predict(tree_model, wineTest, type = "class")

# Afficher les prédictions
head(tree_predictions)

# Calculer la précision
accuracy <- sum(tree_predictions == wineTest$quality) / nrow(wineTest)

# Afficher la précision
print(paste("Précision :", round(accuracy * 100, 2), "%"))
```

## Random Forest Model
```{r}
# Entraîner le modèle de forêts aléatoires
model <- randomForest(quality ~ ., data = wineTrain)

# Prédire sur l'ensemble de test
predictions <- predict(model, wineTest)

# Arrondir les prédictions pour obtenir des nombres entiers
rounded_predictions <- round(predictions)

# Afficher les prédictions
head(rounded_predictions)

# Évaluer le modèle
eval <- postResample(pred = rounded_predictions, obs = wineTest$quality)

# Afficher les métriques d'évaluation
eval
```


```{r}
# Calculer la précision
accuracy <- sum(rounded_predictions == wineTest$quality) / nrow(wineTest)

# Afficher la précision
print(paste("Précision :", round(accuracy * 100, 2), "%"))

# Importer les variables importantes
importance(model)
varImpPlot(model)
mtext("Importance des variables dans le modèle", side = 1, line = 2, cex = 1.2)
```

Dans cette section, nous avons entraîné un modèle de forêts aléatoires pour prédire la qualité du vin.

```{r metrics-logloss}
# y_true = 0 ou 1
y_true <- ifelse(wineTest$quality_binary == "Good", 1, 0)

# Petite fonction pour calculer le log loss
log_loss <- function(y_true, rounded_predictions, eps=1e-15){
  rounded_predictions <- pmin(pmax(rounded_predictions, eps), 1 - eps)
  -mean(y_true * log(rounded_predictions) + (1 - y_true)*log(1 - rounded_predictions))
}

# Log loss pour le random forest
ll_rf <- log_loss(y_true, rounded_predictions)
ll_rf
```

## Interprétation

### RMSE
Le RMSE mesure l'écart moyen entre les valeurs prédites par le modèle et les valeurs réelles. Une valeur de RMSE plus faible indique un meilleur ajustement du modèle aux données. Ici, la valeur est de `r round(eval["RMSE"], 4)`, ce qui signifie qu'en moyenne, les prédictions du modèle s'écartent de `r round(eval["RMSE"], 4)` unités des valeurs réelles.

### Rsquared
Le coefficient de détermination, ou R-squared, représente la proportion de la variance de la variable dépendante qui est prévisible à partir des variables indépendantes. Un R-squared de 1 signifie que le modèle explique parfaitement la variance des données, tandis qu'un R-squared de 0 signifie que le modèle n'explique aucune variance. Ici, la valeur est de `r round(eval["Rsquared"], 4)`, indiquant que le modèle explique environ `r round(eval["Rsquared"] * 100, 2)`% de la variance dans la qualité du vin.

### MAE
Le MAE mesure l'erreur moyenne absolue entre les prédictions et les valeurs réelles. Contrairement au RMSE, il ne pénalise pas autant les grandes erreurs. Ici, la valeur est de `r round(eval["MAE"], 4)`, ce qui signifie qu'en moyenne, les prédictions du modèle s'écartent de `r round(eval["MAE"], 4)` unités des valeurs réelles.

- **Importance des variables** : Nous avons examiné l'importance des différentes variables dans le modèle. Les variables avec des scores d'importance élevés contribuent davantage aux prédictions.

- **Visualisation** : Le graphique d'importance des variables nous permet de voir rapidement quelles caractéristiques sont les plus influentes dans la prédiction de la qualité du vin.





