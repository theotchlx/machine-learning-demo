---
title: "Analyse des Vins Blancs"
output: html_document
---

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(dplyr)
library(caret)
library(randomForest)
library(corrplot)
```

```{r dataset_analysis}
# Charger le jeu de données
winequality_white <- read_delim("dataset/winequality-white.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE)

# Normaliser les noms des colonnes
colnames(winequality_white) <- make.names(colnames(winequality_white))

print(colnames(winequality_white))

# Afficher les dernières lignes du jeu de données
kable(tail(winequality_white))

# Statistiques descriptives
summary(winequality_white)

# Calculer la matrice de corrélation
correlation_matrix <- cor(winequality_white)

# Visualiser la matrice de corrélation
corrplot(correlation_matrix, method = "circle")
```

### Interpreting the results:

This correlation plot shows clearly the correlations between variables.

- A positive correlation (shades of blue) means that if one the variables' value increases, the other increases.
- A negative correlation (shades of red) means that if one of the variables' value increases, the other decreases.

Obviously, wine density is inversely correlated to alcohol content. This can be easily understood when comparing the density of ethanol to that of water:

- Ethanol density : 0.7892 g/mL at 20°C.
- Water density : 0.9982 g/mL at 20°C.

And indeed, if alcohol content is higher, the density lowers, which explains the strong negative correlation.

```{r }
# Calculer la matrice de corrélation
correlation_pairs_matrix <- pairs(winequality_white)

# Test de normalité (Shapiro-Wilk)
shapiro.test(winequality_white$quality)

# Créer une variable binaire pour la qualité
winequality_white$quality_binary <- ifelse(winequality_white$quality >= 6, "Good", "Bad")

# Effectuer le test t de Student
t.test(`alcohol` ~ quality_binary, data = winequality_white)
```

```{r}
# Séparer les données en ensembles d'entraînement et de test
set.seed(123)
trainIndex <- createDataPartition(winequality_white$quality, p = .8,
                                  list = FALSE,
                                  times = 1)
wineTrain <- winequality_white[ trainIndex,]
wineTest  <- winequality_white[-trainIndex,]

wineTrain <- wineTrain[, !(names(wineTrain) %in% c("quality_binary"))]

dim(wineTrain)
dim(wineTest)
```

```{r}
# Entraîner le modèle de forêts aléatoires
model <- randomForest(quality ~ ., data = wineTrain)

# Prédire sur l'ensemble de test
predictions <- predict(model, wineTest)

# Afficher les prédictions
predictions

# Évaluer le modèle
eval <- postResample(pred = predictions, obs = wineTest$quality)

# Afficher les métriques d'évaluation
eval
```

## Interprétation

### RMSE
Le RMSE mesure l'écart moyen entre les valeurs prédites par le modèle et les valeurs réelles. Une valeur de RMSE plus faible indique un meilleur ajustement du modèle aux données. Ici, la valeur est de `r round(eval["RMSE"], 4)`, ce qui signifie qu'en moyenne, les prédictions du modèle s'écartent de `r round(eval["RMSE"], 4)` unités des valeurs réelles.

### Rsquared
Le coefficient de détermination, ou R-squared, représente la proportion de la variance de la variable dépendante qui est prévisible à partir des variables indépendantes. Un R-squared de 1 signifie que le modèle explique parfaitement la variance des données, tandis qu'un R-squared de 0 signifie que le modèle n'explique aucune variance. Ici, la valeur est de `r round(eval["Rsquared"], 4)`, indiquant que le modèle explique environ `r round(eval["Rsquared"] * 100, 2)`% de la variance dans la qualité du vin.

### MAE
Le MAE mesure l'erreur moyenne absolue entre les prédictions et les valeurs réelles. Contrairement au RMSE, il ne pénalise pas autant les grandes erreurs. Ici, la valeur est de `r round(eval["MAE"], 4)`, ce qui signifie qu'en moyenne, les prédictions du modèle s'écartent de `r round(eval["MAE"], 4)` unités des valeurs réelles.

```{r}
# Importer les variables importantes
importance(model)
varImpPlot(model)
mtext("Importance des variables dans le modèle", side = 1, line = 2, cex = 1.2)
```

Dans cette section, nous avons entraîné un modèle de forêts aléatoires pour prédire la qualité du vin.

- **Importance des variables** : Nous avons examiné l'importance des différentes variables dans le modèle. Les variables avec des scores d'importance élevés contribuent davantage aux prédictions.

- **Visualisation** : Le graphique d'importance des variables nous permet de voir rapidement quelles caractéristiques sont les plus influentes dans la prédiction de la qualité du vin.









