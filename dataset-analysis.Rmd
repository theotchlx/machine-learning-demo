---
title: "Wine dataset analysis"
author: "BROINE Thomas, BRONSIN Baptiste, TCHILINGUIRIAN Théo"
date: "2025-02-17"
output: html_document
---

<style type="text/css">

body, td {
   font-size: 16px;
}
code.r{
  font-size: 14px;
}
pre {
  font-size: 14px
}
</style>

```{r setup, include=FALSE}
library(readr)
library(knitr)
library(dplyr)
library(caret)
library(randomForest)
library(corrplot)
library(rpart)
```

## Dataset analysis

We observe that every variable is quantitative.

- **fixed acidity** g(tartaric acid)/dm^3
- **volatile acidity** g(acetic acid)/dm^3
- **Citric acid** g/dm^3
- **Residual sugar** g/dm^3
- **Chlorides** g(sodium chloride)/dm^3
- **Free sulfur dioxide** mg/dm^3
- **Total sulfur dioxide** mg/dm^3
- **Density** g/cm^3
- **pH**
- **Sulphates** g(potassium sulphate)/dm^3
- **Alcohol** vol.%

## Quick summary of the data

```{r dataset_analysis, echo=FALSE}
# Charger le jeu de données
winequality_white <- read_delim("dataset/winequality-white.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE)

# Normaliser les noms des colonnes
colnames(winequality_white) <- make.names(colnames(winequality_white))

# Afficher les dernières lignes du jeu de données
kable(tail(winequality_white))

summary(winequality_white)
```

### Histograms on important variables

Here is an overview of some important variables that will be used for the analysis.

```{r histograms, fig.width=7, fig.height=7, echo=FALSE}
# Exemple d'histogrammes pour quelques variables
par(mfrow=c(2,2))  # pour afficher plusieurs graphes sur une grille 2x2

hist(winequality_white$alcohol, 
     main="Histogram: alcohol", col="skyblue", xlab="Alcohol ( vol.% )")
hist(winequality_white$density,
     main="Histogram: density", col="skyblue", xlab="Density ( g/cm^3 )")
hist(winequality_white$pH,
     main="Histogram: pH", col="skyblue", xlab="pH")
hist(winequality_white$quality, 
     main="Histogram: quality", col="skyblue", xlab="Quality")
```

These histograms display the quantities of some important variables, per their values.

### Boxplots on important variables

The following boxplots show the distribution of some important variables, per the wine quality.

#### Alcohol content

```{r boxplot_alcohol, echo=FALSE}
# Relations entre qualité et alcool.
boxplot(alcohol ~ quality, data=winequality_white,
        main="Alcohol content according to wine quality",
        xlab="Quality", ylab="Alcohol content")
```

This boxplot shows that generally, higher wine qualities have higher alcohol content. The best quality of wine has a consistant high value in alcohol content.  
However, it is important to note that there are very few data on higher quality wine (as can be seen in the above histograms).

#### Density

```{r boxplot_density, echo=FALSE}
# Relations entre qualité et densité
boxplot(density ~ quality, data=winequality_white, ylim=c(0.98, 1.01),
        main="Density according to wine quality",
        xlab="Quality", col="skyblue", ylab="Density")
```

This boxplot shows that higher wine qualities have lower density (that is, different contents such as sugars, alcohol, and other chemicals). The best quality of wine has a consistant low density.

### Correlation

This correlation plot shows the correlation between variables.

```{r correlation, echo=FALSE}
# Calculer la matrice de corrélation
correlation_matrix <- cor(winequality_white)

# Visualiser la matrice de corrélation
corrplot(correlation_matrix, method = "circle")
```

#### Interpreting the results:

This correlation plot shows clearly the correlations between variables.

- A positive correlation (shades of blue) means that if one the variables' value increases, the other increases.
- A negative correlation (shades of red) means that if one of the variables' value increases, the other decreases.

Obviously, wine density is inversely correlated to alcohol content. This can be easily understood when comparing the density of ethanol to that of water:

- Ethanol density : 0.7892 g/mL at 20°C.
- Water density : 0.9982 g/mL at 20°C.

And indeed, if alcohol content is higher, the density lowers, which explains the strong negative correlation.

Other obvious correlations include acidity and pH, density and residual sugar content

Basically, the density is explained by the wine's contents (alcohol, sugars, sulphates, chlorides). Thankfully for this small dataset, the correlation between these variables will not influence the wine quality prediction. For this small dataset, we don't need to eliminate variables for predictions.

## Logistic binary regression

Now, we will do a binary logistic regression for predictive analysis.

First, we classify the quality as binary.

```{r}
winequality_white$quality_binary <- ifelse(winequality_white$quality <= 5, "bad", "good")

# We want a factor (category)
winequality_white$quality_binary <- as.factor(winequality_white$quality_binary)
```

```{r}
# Separate the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(winequality_white$quality, p = .8,
                                  list = FALSE,
                                  times = 1)
wineTrain <- winequality_white[ trainIndex,]
wineTest  <- winequality_white[-trainIndex,]

wineTrain_withoutQuality <- wineTrain[, !(names(wineTrain) %in% c("quality"))]
wineTrain_withoutQualityBinary <- wineTrain[, !(names(wineTrain) %in% c("quality_binary"))]

wineTest_withoutQuality <- wineTest[, !(names(wineTest) %in% c("quality"))]
wineTest_withoutQualityBinary <- wineTest[, !(names(wineTest) %in% c("quality_binary"))]
wineTest_WithoutAllQuality <- wineTest[, !(names(wineTest) %in% c("quality", "quality_binary"))]

dim(wineTrain)
dim(wineTest)
```

```{r logistic_binary_regression}
# Binary logistic regression
logit_model <- glm(quality_binary ~ fixed.acidity + volatile.acidity + 
                                     citric.acid + residual.sugar + chlorides + 
                                     free.sulfur.dioxide + total.sulfur.dioxide + 
                                     density + pH + sulphates + alcohol,
                   data = wineTrain_withoutQuality, # We need here to predict the binary quality
                   family = binomial)

# Résumé du modèle
summary(logit_model)

# Prédiction sur l'ensemble de test (probabilité d'être "bon")
predict_prob_logit <- predict(logit_model, newdata = wineTest_WithoutAllQuality, type = "response") # We remove all quality clues

# Pour obtenir la classe prédite (0/1) selon un cutoff=0.5
predict_class_logit <- ifelse(predict_prob_logit <= 0.5, "bad", "good")
predict_class_logit <- factor(predict_class_logit, levels = c("bad", "good"))

# Table de confusion
conf_mat_logit <- table(Predicted = predict_class_logit, 
                        Actual = wineTest$quality_binary)
conf_mat_logit

# Accuracy
accuracy_logit <- sum(diag(conf_mat_logit)) / sum(conf_mat_logit)
accuracy_logit
```

## Decision Tree Model
```{r}
# Entraîner le modèle avec un seul arbre de décision
tree_model <- rpart(quality ~ ., data = wineTrain_withoutQualityBinary, method = "class") # We need here to predict the quality

# Afficher l'arbre de décision
print(tree_model)

# Faire des prédictions sur l'ensemble de test
tree_predictions <- predict(tree_model, wineTest_WithoutAllQuality, type = "class") # We remove all quality clues

# Afficher les prédictions
head(tree_predictions)

# Calculer la précision
accuracy <- sum(tree_predictions == wineTest$quality) / nrow(wineTest)

# Afficher la précision
print(paste("Précision :", round(accuracy * 100, 2), "%"))
```

There are two types of log loss calculations: one for binary classification problems and one for multi-class classification problems. In this case, we have a binary classification problem, so we will use the log loss formula for binary classification.

```{r decision-tree-logloss}
y_true <- ifelse(wineTest$quality_binary == "good", 1, 0)

# Convertir les facteurs en numériques
tree_predictions_numeric <- as.numeric(as.character(tree_predictions))

# Convertir les scores de qualité en probabilités
probabilities <- tree_predictions_numeric / 10

# Fonction pour calculer le log loss
log_loss <- function(y_true, probabilities, eps=1e-15){
  probabilities <- pmin(pmax(probabilities, eps), 1 - eps)
  -mean(y_true * log(probabilities) + (1 - y_true) * log(1 - probabilities))
}

# Calcul de la log loss
ll_rf <- log_loss(y_true, probabilities)
print(paste("Log loss :", ll_rf))
```

We also calculate the Brier score of the model.
```{r brier_tree}
# Calculer Brier score pour le modèle decision tree
tree_probabilities <- predict(tree_model, wineTest_WithoutAllQuality, type = "prob")
brier_score_tree <- mean((tree_probabilities[, 2] - y_true)^2)
print(paste("Brier Score (Decision Tree):", round(brier_score_tree, 4)))
```

## Random Forest Model
```{r}
# Entraîner le modèle de forêts aléatoires
randomForestModel <- randomForest(quality ~ ., data = wineTrain_withoutQualityBinary)

# Prédire sur l'ensemble de test
predictions <- predict(randomForestModel, wineTest_WithoutAllQuality)

# Arrondir les prédictions pour obtenir des nombres entiers
rounded_predictions <- round(predictions)

# Afficher les prédictions
head(rounded_predictions)

# Évaluer le modèle
eval <- postResample(pred = rounded_predictions, obs = wineTest$quality)

# Afficher les métriques d'évaluation
eval
```

```{r}
# Calculer la précision
accuracy <- sum(rounded_predictions == wineTest$quality) / nrow(wineTest)

# Afficher la précision
print(paste("Précision :", round(accuracy * 100, 2), "%"))

# Importer les variables importantes
importance(randomForestModel)
varImpPlot(randomForestModel)
mtext("Importance des variables dans le modèle", side = 1, line = 2, cex = 1.2)
```

Dans cette section, nous avons entraîné un modèle de forêts aléatoires pour prédire la qualité du vin.

```{r metrics-logloss}
# Convertir les scores de qualité en probabilités
probabilities <- rounded_predictions / 10

# Calcul de la log loss
ll_rf <- log_loss(y_true, probabilities)
print(paste("Log loss :", ll_rf))
```

Le log loss binaire est une mesure de performance utilisée pour évaluer la précision des prédictions probabilistes d'un modèle de classification binaire, en comparant les probabilités prédites à la véritable classe (0 ou 1) de chaque échantillon.

And we calculate the Brier score as well.
```{r brier_forest}
# Calculer le Brier score pour le modèle de forêts aléatoires
# rf_probabilities <- predict(randomForestModel, wineTest_WithoutAllQuality, type = "prob") # ERROR on type = prob
# brier_score_rf <- mean((rf_probabilities[, 2] - y_true)^2)
# print(paste("Brier Score (Random Forest):", round(brier_score_rf, 4)))
```

## Interprétation

### RMSE
Le RMSE mesure l'écart moyen entre les valeurs prédites par le modèle et les valeurs réelles. Une valeur de RMSE plus faible indique un meilleur ajustement du modèle aux données. Ici, la valeur est de `r round(eval["RMSE"], 4)`, ce qui signifie qu'en moyenne, les prédictions du modèle s'écartent de `r round(eval["RMSE"], 4)` unités des valeurs réelles.

### Rsquared
Le coefficient de détermination, ou R-squared, représente la proportion de la variance de la variable dépendante qui est prévisible à partir des variables indépendantes. Un R-squared de 1 signifie que le modèle explique parfaitement la variance des données, tandis qu'un R-squared de 0 signifie que le modèle n'explique aucune variance. Ici, la valeur est de `r round(eval["Rsquared"], 4)`, indiquant que le modèle explique environ `r round(eval["Rsquared"] * 100, 2)`% de la variance dans la qualité du vin.

### MAE
Le MAE mesure l'erreur moyenne absolue entre les prédictions et les valeurs réelles. Contrairement au RMSE, il ne pénalise pas autant les grandes erreurs. Ici, la valeur est de `r round(eval["MAE"], 4)`, ce qui signifie qu'en moyenne, les prédictions du modèle s'écartent de `r round(eval["MAE"], 4)` unités des valeurs réelles.

- **Importance des variables** : Nous avons examiné l'importance des différentes variables dans le modèle. Les variables avec des scores d'importance élevés contribuent davantage aux prédictions.

- **Visualisation** : Le graphique d'importance des variables nous permet de voir rapidement quelles caractéristiques sont les plus influentes dans la prédiction de la qualité du vin.

use the pairs function
see readme for more to do
do what u think is good. Explain why. Explain your understanding.

